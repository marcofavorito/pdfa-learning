{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PDFAs and learning algorithms Install To install the package from PyPI: pip install pdfa_learning Setup Make sure you have Python 3.7+ on your platform. Install Poetry Clone the repository and enter it: git clone https://github.com/marcofavorito/pdfa-learning.git && cd pdfa-learning Set up the Python virtual environment: poetry shell && poetry install Install Graphviz if you want to use the rendering features. Quickstart Please have a look at the notebooks/ to see how to use the code. Tests To run tests: tox To run only the code tests: tox -e py3.7 To run only the linters: - tox -e flake8 - tox -e mypy - tox -e black-check - tox -e isort-check Docs To build the docs: mkdocs build To view documentation in a browser: mkdocs serve and then go to http://localhost:8000 License pdfa-learning is released under the GNU General Public License v3.0 or later (GPLv3+). Copyright 2020 Marco Favorito Authors Marco Favorito","title":"Home"},{"location":"#install","text":"To install the package from PyPI: pip install pdfa_learning","title":"Install"},{"location":"#setup","text":"Make sure you have Python 3.7+ on your platform. Install Poetry Clone the repository and enter it: git clone https://github.com/marcofavorito/pdfa-learning.git && cd pdfa-learning Set up the Python virtual environment: poetry shell && poetry install Install Graphviz if you want to use the rendering features.","title":"Setup"},{"location":"#quickstart","text":"Please have a look at the notebooks/ to see how to use the code.","title":"Quickstart"},{"location":"#tests","text":"To run tests: tox To run only the code tests: tox -e py3.7 To run only the linters: - tox -e flake8 - tox -e mypy - tox -e black-check - tox -e isort-check","title":"Tests"},{"location":"#docs","text":"To build the docs: mkdocs build To view documentation in a browser: mkdocs serve and then go to http://localhost:8000","title":"Docs"},{"location":"#license","text":"pdfa-learning is released under the GNU General Public License v3.0 or later (GPLv3+). Copyright 2020 Marco Favorito","title":"License"},{"location":"#authors","text":"Marco Favorito","title":"Authors"},{"location":"notebooks/01-pdfa/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); PDFA In this notebook, we will see how to use the PDFA class. Example Utility functions to display SVGs. % matplotlib inline import numpy as np from pdfa_learning.pdfa import PDFA from helpers import render_automaton The following automaton captures all the sequences of only heads, followed by one tail. def make_automaton ( p : float = 0.5 ) -> PDFA : \"\"\" Make the PDFA for the heads and tail example. :param p: the probability of getting head. :return: the PDFA. \"\"\" return PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 ) } } ) automaton = make_automaton ( 0.5 ) render_automaton ( automaton ) %3 fake 0 0 fake->0 0->0 0, 0.5 1 1 0->1 1, 0.5 -1 -1 1->-1 -1, 1.0 Sample a word from the PDFA above. automaton . sample () [1, -1] With probability p = 0.5 p = 0.5 the trace stops. Hence, The average length of the trace is: 1 + \\sum\\limits_{n=1}^{\\infty} n\\cdot p^{n-1}p = 1 + \\frac{1}{p} 1 + \\sum\\limits_{n=1}^{\\infty} n\\cdot p^{n-1}p = 1 + \\frac{1}{p} Which for p=\\frac{1}{2} p=\\frac{1}{2} , it is 3 3 ( +1 +1 is used to count the termination symbol). ps = [ 0.1 , 0.5 , 0.9 ] expected_length = lambda x : 1 + 1 / x nb_samples = 10000 for p in ps : stop_probability = 1 - p _automaton = make_automaton ( stop_probability ) samples = [ _automaton . sample () for _ in range ( nb_samples )] average_length = np . mean ([ len ( l ) for l in samples ]) print ( f \"The average length of the samples is: { average_length : 5.2f } . Expected: { expected_length ( p ) : 5.2f } .\" ) The average length of the samples is: 10.80. Expected: 11.00. The average length of the samples is: 3.01. Expected: 3.00. The average length of the samples is: 2.11. Expected: 2.11.","title":"Build a PDFA"},{"location":"notebooks/01-pdfa/#pdfa","text":"In this notebook, we will see how to use the PDFA class.","title":"PDFA"},{"location":"notebooks/01-pdfa/#example","text":"Utility functions to display SVGs. % matplotlib inline import numpy as np from pdfa_learning.pdfa import PDFA from helpers import render_automaton The following automaton captures all the sequences of only heads, followed by one tail. def make_automaton ( p : float = 0.5 ) -> PDFA : \"\"\" Make the PDFA for the heads and tail example. :param p: the probability of getting head. :return: the PDFA. \"\"\" return PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 ) } } ) automaton = make_automaton ( 0.5 ) render_automaton ( automaton ) %3 fake 0 0 fake->0 0->0 0, 0.5 1 1 0->1 1, 0.5 -1 -1 1->-1 -1, 1.0 Sample a word from the PDFA above. automaton . sample () [1, -1] With probability p = 0.5 p = 0.5 the trace stops. Hence, The average length of the trace is: 1 + \\sum\\limits_{n=1}^{\\infty} n\\cdot p^{n-1}p = 1 + \\frac{1}{p} 1 + \\sum\\limits_{n=1}^{\\infty} n\\cdot p^{n-1}p = 1 + \\frac{1}{p} Which for p=\\frac{1}{2} p=\\frac{1}{2} , it is 3 3 ( +1 +1 is used to count the termination symbol). ps = [ 0.1 , 0.5 , 0.9 ] expected_length = lambda x : 1 + 1 / x nb_samples = 10000 for p in ps : stop_probability = 1 - p _automaton = make_automaton ( stop_probability ) samples = [ _automaton . sample () for _ in range ( nb_samples )] average_length = np . mean ([ len ( l ) for l in samples ]) print ( f \"The average length of the samples is: { average_length : 5.2f } . Expected: { expected_length ( p ) : 5.2f } .\" ) The average length of the samples is: 10.80. Expected: 11.00. The average length of the samples is: 3.01. Expected: 3.00. The average length of the samples is: 2.11. Expected: 2.11.","title":"Example"},{"location":"notebooks/02-pdfa-learning-palmer/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); PDFA Learning (Palmer & Goldberg, 2005) Note : this implementation is deprecated. Consider using the implementation of the Balle's algorithm (see the next documentation page) In this notebook, we will show how to use the implementation of PDFA learning, as described in [1]. Example Utility functions to display SVGs. % matplotlib inline from pprint import pprint from helpers import render_automaton from pdfa_learning.learn_pdfa.base import learn_pdfa , Algorithm from pdfa_learning.learn_pdfa.utils.generator import MultiprocessedGenerator , SimpleGenerator from pdfa_learning.pdfa import PDFA [2021-01-02 16:14:37,642][matplotlib.pyplot][DEBUG] Loaded backend module://ipykernel.pylab.backend_inline version unknown. Example with 1 state. Let's use the following automaton to generate samples. p = 0.3 automaton = PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 )} } ) render_automaton ( automaton ) [2021-01-02 16:14:39,452][graphviz.files][DEBUG] write 195 bytes to '/tmp/tmpgcaox75a/output' [2021-01-02 16:14:39,455][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.3 1 1 0->1 1, 0.7 -1 -1 1->-1 -1, 1.0 Now we will run the PAC learning algorithm to learn the above automaton. MultiprocessedGenerator wraps the automaton and generates samples using multiple processes; learn_pdfa is the main entrypoint of the algorithm implementation. n1_max_debug is the maximum number for N_1 N_1 (for the subgraph learning) n2_max_debug is the maximum number for N_2 N_2 (for the probabilities learning) m0_max_debug is the maximum number for m_0 m_0 (for multiset filtering) generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . PALMER , sample_generator = generator , alphabet_size = 2 , epsilon = 0.2 , delta_1 = 0.2 , delta_2 = 0.2 , mu = 0.1 , n = 3 , n1_max_debug = 100000 , n2_max_debug = 100000 , m0_max_debug = 100000 / 10 , ) [2021-01-02 16:14:40,743][pdfa_learning.learn_pdfa][INFO] Parameters: ('PalmerParams(sample_generator=<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator ' 'object at 0x7f2aabd60f10>, alphabet_size=2, epsilon=0.2, delta_1=0.2, ' 'delta_2=0.2, mu=0.1, n=3, m0_max_debug=10000.0, n1_max_debug=100000, ' 'n2_max_debug=100000)') [2021-01-02 16:14:40,745][pdfa_learning.learn_pdfa][INFO] N1 = 54432.579348157145, N2 = 55998960.0. Chosen: 55998960 [2021-01-02 16:14:40,745][pdfa_learning.learn_pdfa][INFO] m0 = 466658 [2021-01-02 16:14:40,746][pdfa_learning.learn_pdfa][INFO] N = 55998960 [2021-01-02 16:14:40,746][pdfa_learning.learn_pdfa][INFO] using m0 = 10000.0, N = 100000 [2021-01-02 16:14:42,789][pdfa_learning.learn_pdfa][INFO] Sampling done. [2021-01-02 16:14:42,790][pdfa_learning.learn_pdfa][INFO] Number of samples: 100000. [2021-01-02 16:14:42,793][pdfa_learning.learn_pdfa][INFO] Avg. length of samples: 2.43472. [2021-01-02 16:14:42,908][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 16:14:43,152][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 16:14:43,307][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 16:14:43,435][pdfa_learning.learn_pdfa][INFO] Vertices: {0, 1} [2021-01-02 16:14:43,436][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 0, 1: 1}, 1: {-1: -1}} [2021-01-02 16:14:43,436][pdfa_learning.learn_pdfa][INFO] Computed final node: -1 (no outgoing transitions) [2021-01-02 16:14:43,438][pdfa_learning.learn_pdfa][INFO] Number of vertices: 2. [2021-01-02 16:14:43,439][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 0, 1: 1}, 1: {-1: -1}}. [2021-01-02 16:14:43,440][pdfa_learning.learn_pdfa][INFO] Start learning probabilities. [2021-01-02 16:14:43,440][pdfa_learning.learn_pdfa][INFO] Sample size: 21734484183613. [2021-01-02 16:14:43,441][pdfa_learning.learn_pdfa][INFO] Using N = 100000. [2021-01-02 16:14:45,992][pdfa_learning.learn_pdfa][INFO] Computed vertices: {0, 1} [2021-01-02 16:14:45,993][pdfa_learning.learn_pdfa][INFO] Computed transition dictionary: {0: {-1: (-1, 0.0), 0: (0, 0.30019034822528273), 1: (1, 0.6998096517747173)}, 1: {-1: (-1, 1.0)}} The learned automaton is: print ( \"Transitions: \" ) pprint ( pdfa . transitions ) render_automaton ( pdfa ) [2021-01-02 16:14:46,001][graphviz.files][DEBUG] write 203 bytes to '/tmp/tmpgq7qad18/output' [2021-01-02 16:14:46,067][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] Transitions: {(0, -1, 0.0, -1), (0, 0, 0.30019034822528273, 0), (0, 1, 0.6998096517747173, 1), (1, -1, 1.0, -1)} %3 fake 0 0 fake->0 0->0 0, 0.30019 1 1 0->1 1, 0.69981 -1 -1 1->-1 -1, 1.0 Example with 2 states. Now let's try to learn the following automaton: p1 = 0.4 p2 = 0.7 automaton = PDFA ( 3 , 2 , { 0 : { 0 : ( 1 , p1 ), 1 : ( 2 , 1 - p1 ), }, 1 : { 0 : ( 2 , 1 - p2 ), 1 : ( 1 , p2 ), }, 2 : { - 1 : ( - 1 , 1.0 ) } }, ) render_automaton ( automaton ) [2021-01-02 16:14:46,168][graphviz.files][DEBUG] write 248 bytes to '/tmp/tmp1ryjqa9g/output' [2021-01-02 16:14:46,170][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 1 1 0->1 0, 0.4 2 2 0->2 1, 0.6 1->1 1, 0.7 1->2 0, 0.3 -1 -1 2->-1 -1, 1.0 generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . PALMER , sample_generator = generator , alphabet_size = 2 , epsilon = 0.2 , delta_1 = 0.2 , delta_2 = 0.2 , mu = 0.1 , n = 3 , n1_max_debug = 3000000 , n2_max_debug = 1000000 , m0_max_debug = 3000000 / 10 , ) [2021-01-02 16:14:46,289][pdfa_learning.learn_pdfa][INFO] Parameters: ('PalmerParams(sample_generator=<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator ' 'object at 0x7f2a76456710>, alphabet_size=2, epsilon=0.2, delta_1=0.2, ' 'delta_2=0.2, mu=0.1, n=3, m0_max_debug=300000.0, n1_max_debug=3000000, ' 'n2_max_debug=1000000)') [2021-01-02 16:14:46,291][pdfa_learning.learn_pdfa][INFO] N1 = 54432.579348157145, N2 = 55998960.0. Chosen: 55998960 [2021-01-02 16:14:46,292][pdfa_learning.learn_pdfa][INFO] m0 = 466658 [2021-01-02 16:14:46,293][pdfa_learning.learn_pdfa][INFO] N = 55998960 [2021-01-02 16:14:46,294][pdfa_learning.learn_pdfa][INFO] using m0 = 300000.0, N = 3000000 [2021-01-02 16:17:14,294][pdfa_learning.learn_pdfa][INFO] Sampling done. [2021-01-02 16:17:14,296][pdfa_learning.learn_pdfa][INFO] Number of samples: 3000000. [2021-01-02 16:17:14,417][pdfa_learning.learn_pdfa][INFO] Avg. length of samples: 3.3331573333333333. [2021-01-02 16:17:18,827][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 16:17:30,301][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 16:17:37,928][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 16:17:47,846][pdfa_learning.learn_pdfa][INFO] Iteration 3 [2021-01-02 16:17:58,387][pdfa_learning.learn_pdfa][INFO] Iteration 4 [2021-01-02 16:18:06,808][pdfa_learning.learn_pdfa][INFO] Vertices: {0, 1, 2} [2021-01-02 16:18:06,811][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 2, 1: 1}, 1: {-1: -1}, 2: {-1: -1, 0: 1, 1: 2}} [2021-01-02 16:18:06,813][pdfa_learning.learn_pdfa][INFO] Computed final node: -1 (no outgoing transitions) [2021-01-02 16:18:06,903][pdfa_learning.learn_pdfa][INFO] Number of vertices: 3. [2021-01-02 16:18:06,904][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 2, 1: 1}, 1: {-1: -1}, 2: {-1: -1, 0: 1, 1: 2}}. [2021-01-02 16:18:06,904][pdfa_learning.learn_pdfa][INFO] Start learning probabilities. [2021-01-02 16:18:06,905][pdfa_learning.learn_pdfa][INFO] Sample size: 21734484183613. [2021-01-02 16:18:06,906][pdfa_learning.learn_pdfa][INFO] Using N = 1000000. [2021-01-02 16:19:04,326][pdfa_learning.learn_pdfa][INFO] Computed vertices: {0, 1, 2} [2021-01-02 16:19:04,327][pdfa_learning.learn_pdfa][INFO] Computed transition dictionary: {0: {-1: (-1, 0.0), 0: (2, 0.399264), 1: (1, 0.600736)}, 1: {-1: (-1, 1.0)}, 2: {-1: (-1, 0.0), 0: (1, 0.30008658425128676), 1: (2, 0.6999134157487132)}} render_automaton ( pdfa ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-5f1d6655d94a> in <module> ----> 1 render_automaton ( pdfa ) NameError : name 'render_automaton' is not defined Palmer N., Goldberg P.W. (2005) PAC-Learnability of Probabilistic Deterministic Finite State Automata in Terms of Variation Distance. In: Jain S., Simon H.U., Tomita E. (eds) Algorithmic Learning Theory. ALT 2005. Lecture Notes in Computer Science, vol 3734. Springer, Berlin, Heidelberg. https://doi.org/10.1007/11564089_14","title":"Learn a PDFA using (Palmer & Goldberg, 2005)"},{"location":"notebooks/02-pdfa-learning-palmer/#pdfa-learning-palmer-goldberg-2005","text":"Note : this implementation is deprecated. Consider using the implementation of the Balle's algorithm (see the next documentation page) In this notebook, we will show how to use the implementation of PDFA learning, as described in [1].","title":"PDFA Learning  (Palmer &amp; Goldberg, 2005)"},{"location":"notebooks/02-pdfa-learning-palmer/#example","text":"Utility functions to display SVGs. % matplotlib inline from pprint import pprint from helpers import render_automaton from pdfa_learning.learn_pdfa.base import learn_pdfa , Algorithm from pdfa_learning.learn_pdfa.utils.generator import MultiprocessedGenerator , SimpleGenerator from pdfa_learning.pdfa import PDFA [2021-01-02 16:14:37,642][matplotlib.pyplot][DEBUG] Loaded backend module://ipykernel.pylab.backend_inline version unknown.","title":"Example"},{"location":"notebooks/02-pdfa-learning-palmer/#example-with-1-state","text":"Let's use the following automaton to generate samples. p = 0.3 automaton = PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 )} } ) render_automaton ( automaton ) [2021-01-02 16:14:39,452][graphviz.files][DEBUG] write 195 bytes to '/tmp/tmpgcaox75a/output' [2021-01-02 16:14:39,455][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.3 1 1 0->1 1, 0.7 -1 -1 1->-1 -1, 1.0 Now we will run the PAC learning algorithm to learn the above automaton. MultiprocessedGenerator wraps the automaton and generates samples using multiple processes; learn_pdfa is the main entrypoint of the algorithm implementation. n1_max_debug is the maximum number for N_1 N_1 (for the subgraph learning) n2_max_debug is the maximum number for N_2 N_2 (for the probabilities learning) m0_max_debug is the maximum number for m_0 m_0 (for multiset filtering) generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . PALMER , sample_generator = generator , alphabet_size = 2 , epsilon = 0.2 , delta_1 = 0.2 , delta_2 = 0.2 , mu = 0.1 , n = 3 , n1_max_debug = 100000 , n2_max_debug = 100000 , m0_max_debug = 100000 / 10 , ) [2021-01-02 16:14:40,743][pdfa_learning.learn_pdfa][INFO] Parameters: ('PalmerParams(sample_generator=<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator ' 'object at 0x7f2aabd60f10>, alphabet_size=2, epsilon=0.2, delta_1=0.2, ' 'delta_2=0.2, mu=0.1, n=3, m0_max_debug=10000.0, n1_max_debug=100000, ' 'n2_max_debug=100000)') [2021-01-02 16:14:40,745][pdfa_learning.learn_pdfa][INFO] N1 = 54432.579348157145, N2 = 55998960.0. Chosen: 55998960 [2021-01-02 16:14:40,745][pdfa_learning.learn_pdfa][INFO] m0 = 466658 [2021-01-02 16:14:40,746][pdfa_learning.learn_pdfa][INFO] N = 55998960 [2021-01-02 16:14:40,746][pdfa_learning.learn_pdfa][INFO] using m0 = 10000.0, N = 100000 [2021-01-02 16:14:42,789][pdfa_learning.learn_pdfa][INFO] Sampling done. [2021-01-02 16:14:42,790][pdfa_learning.learn_pdfa][INFO] Number of samples: 100000. [2021-01-02 16:14:42,793][pdfa_learning.learn_pdfa][INFO] Avg. length of samples: 2.43472. [2021-01-02 16:14:42,908][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 16:14:43,152][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 16:14:43,307][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 16:14:43,435][pdfa_learning.learn_pdfa][INFO] Vertices: {0, 1} [2021-01-02 16:14:43,436][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 0, 1: 1}, 1: {-1: -1}} [2021-01-02 16:14:43,436][pdfa_learning.learn_pdfa][INFO] Computed final node: -1 (no outgoing transitions) [2021-01-02 16:14:43,438][pdfa_learning.learn_pdfa][INFO] Number of vertices: 2. [2021-01-02 16:14:43,439][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 0, 1: 1}, 1: {-1: -1}}. [2021-01-02 16:14:43,440][pdfa_learning.learn_pdfa][INFO] Start learning probabilities. [2021-01-02 16:14:43,440][pdfa_learning.learn_pdfa][INFO] Sample size: 21734484183613. [2021-01-02 16:14:43,441][pdfa_learning.learn_pdfa][INFO] Using N = 100000. [2021-01-02 16:14:45,992][pdfa_learning.learn_pdfa][INFO] Computed vertices: {0, 1} [2021-01-02 16:14:45,993][pdfa_learning.learn_pdfa][INFO] Computed transition dictionary: {0: {-1: (-1, 0.0), 0: (0, 0.30019034822528273), 1: (1, 0.6998096517747173)}, 1: {-1: (-1, 1.0)}} The learned automaton is: print ( \"Transitions: \" ) pprint ( pdfa . transitions ) render_automaton ( pdfa ) [2021-01-02 16:14:46,001][graphviz.files][DEBUG] write 203 bytes to '/tmp/tmpgq7qad18/output' [2021-01-02 16:14:46,067][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] Transitions: {(0, -1, 0.0, -1), (0, 0, 0.30019034822528273, 0), (0, 1, 0.6998096517747173, 1), (1, -1, 1.0, -1)} %3 fake 0 0 fake->0 0->0 0, 0.30019 1 1 0->1 1, 0.69981 -1 -1 1->-1 -1, 1.0","title":"Example with 1 state."},{"location":"notebooks/02-pdfa-learning-palmer/#example-with-2-states","text":"Now let's try to learn the following automaton: p1 = 0.4 p2 = 0.7 automaton = PDFA ( 3 , 2 , { 0 : { 0 : ( 1 , p1 ), 1 : ( 2 , 1 - p1 ), }, 1 : { 0 : ( 2 , 1 - p2 ), 1 : ( 1 , p2 ), }, 2 : { - 1 : ( - 1 , 1.0 ) } }, ) render_automaton ( automaton ) [2021-01-02 16:14:46,168][graphviz.files][DEBUG] write 248 bytes to '/tmp/tmp1ryjqa9g/output' [2021-01-02 16:14:46,170][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 1 1 0->1 0, 0.4 2 2 0->2 1, 0.6 1->1 1, 0.7 1->2 0, 0.3 -1 -1 2->-1 -1, 1.0 generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . PALMER , sample_generator = generator , alphabet_size = 2 , epsilon = 0.2 , delta_1 = 0.2 , delta_2 = 0.2 , mu = 0.1 , n = 3 , n1_max_debug = 3000000 , n2_max_debug = 1000000 , m0_max_debug = 3000000 / 10 , ) [2021-01-02 16:14:46,289][pdfa_learning.learn_pdfa][INFO] Parameters: ('PalmerParams(sample_generator=<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator ' 'object at 0x7f2a76456710>, alphabet_size=2, epsilon=0.2, delta_1=0.2, ' 'delta_2=0.2, mu=0.1, n=3, m0_max_debug=300000.0, n1_max_debug=3000000, ' 'n2_max_debug=1000000)') [2021-01-02 16:14:46,291][pdfa_learning.learn_pdfa][INFO] N1 = 54432.579348157145, N2 = 55998960.0. Chosen: 55998960 [2021-01-02 16:14:46,292][pdfa_learning.learn_pdfa][INFO] m0 = 466658 [2021-01-02 16:14:46,293][pdfa_learning.learn_pdfa][INFO] N = 55998960 [2021-01-02 16:14:46,294][pdfa_learning.learn_pdfa][INFO] using m0 = 300000.0, N = 3000000 [2021-01-02 16:17:14,294][pdfa_learning.learn_pdfa][INFO] Sampling done. [2021-01-02 16:17:14,296][pdfa_learning.learn_pdfa][INFO] Number of samples: 3000000. [2021-01-02 16:17:14,417][pdfa_learning.learn_pdfa][INFO] Avg. length of samples: 3.3331573333333333. [2021-01-02 16:17:18,827][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 16:17:30,301][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 16:17:37,928][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 16:17:47,846][pdfa_learning.learn_pdfa][INFO] Iteration 3 [2021-01-02 16:17:58,387][pdfa_learning.learn_pdfa][INFO] Iteration 4 [2021-01-02 16:18:06,808][pdfa_learning.learn_pdfa][INFO] Vertices: {0, 1, 2} [2021-01-02 16:18:06,811][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 2, 1: 1}, 1: {-1: -1}, 2: {-1: -1, 0: 1, 1: 2}} [2021-01-02 16:18:06,813][pdfa_learning.learn_pdfa][INFO] Computed final node: -1 (no outgoing transitions) [2021-01-02 16:18:06,903][pdfa_learning.learn_pdfa][INFO] Number of vertices: 3. [2021-01-02 16:18:06,904][pdfa_learning.learn_pdfa][INFO] Transitions: {0: {-1: -1, 0: 2, 1: 1}, 1: {-1: -1}, 2: {-1: -1, 0: 1, 1: 2}}. [2021-01-02 16:18:06,904][pdfa_learning.learn_pdfa][INFO] Start learning probabilities. [2021-01-02 16:18:06,905][pdfa_learning.learn_pdfa][INFO] Sample size: 21734484183613. [2021-01-02 16:18:06,906][pdfa_learning.learn_pdfa][INFO] Using N = 1000000. [2021-01-02 16:19:04,326][pdfa_learning.learn_pdfa][INFO] Computed vertices: {0, 1, 2} [2021-01-02 16:19:04,327][pdfa_learning.learn_pdfa][INFO] Computed transition dictionary: {0: {-1: (-1, 0.0), 0: (2, 0.399264), 1: (1, 0.600736)}, 1: {-1: (-1, 1.0)}, 2: {-1: (-1, 0.0), 0: (1, 0.30008658425128676), 1: (2, 0.6999134157487132)}} render_automaton ( pdfa ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-5f1d6655d94a> in <module> ----> 1 render_automaton ( pdfa ) NameError : name 'render_automaton' is not defined Palmer N., Goldberg P.W. (2005) PAC-Learnability of Probabilistic Deterministic Finite State Automata in Terms of Variation Distance. In: Jain S., Simon H.U., Tomita E. (eds) Algorithmic Learning Theory. ALT 2005. Lecture Notes in Computer Science, vol 3734. Springer, Berlin, Heidelberg. https://doi.org/10.1007/11564089_14","title":"Example with 2 states."},{"location":"notebooks/03-pdfa-learning-balle/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); PDFA Learning (Balle et al., 2013) In this notebook, we will show how to use the implementation of PDFA learning, as described in [2]. In terms of APIs, the only things that change are the parameter algorithm to learn_pdfa (it must be Algorithm.BALLE ) and the set of parameters. See pdfa_learning.learn_pdfa.balle.params.py for all the details. Example Utility functions to display SVGs. % matplotlib inline from pprint import pprint from helpers import render_automaton from pdfa_learning.learn_pdfa.base import learn_pdfa , Algorithm from pdfa_learning.learn_pdfa.utils.generator import MultiprocessedGenerator , SimpleGenerator from pdfa_learning.pdfa import PDFA Example with 1 state. Let's use the following automaton to generate samples. p = 0.3 automaton = PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 )} } ) render_automaton ( automaton ) [2021-01-02 15:36:50,713][graphviz.files][DEBUG] write 195 bytes to '/tmp/tmp4krev1q6/output' [2021-01-02 15:36:50,715][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.3 1 1 0->1 1, 0.7 -1 -1 1->-1 -1, 1.0 Now we will run the PAC learning algorithm to learn the above automaton. With respect to the previous guide, we have the following parameters: nb_samples is the number of samples. delta : is the probability of failure. n : is the upperbound on the number of states. generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . BALLE , sample_generator = generator , alphabet_size = automaton . alphabet_size , nb_samples = 20000 , delta = 0.1 , n = 10 , ) [2021-01-02 15:36:54,341][pdfa_learning.learn_pdfa][INFO] Parameters: (\"{'alphabet_size': 2,\\n\" \" 'dataset_size': None,\\n\" \" 'delta': 0.1,\\n\" \" 'epsilon': 0.1,\\n\" \" 'n': 10,\\n\" \" 'nb_samples': 20000,\\n\" \" 'sample_generator': \" '<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator object at ' '0x7f5410c6bf50>,\\n' \" 'with_ground': False,\\n\" \" 'with_infty_norm': True,\\n\" \" 'with_smoothing': False}\") [2021-01-02 15:36:54,343][pdfa_learning.learn_pdfa][INFO] Generating the sample. [2021-01-02 15:36:54,737][pdfa_learning.learn_pdfa][INFO] Average trace length: 2.4088. [2021-01-02 15:36:54,738][pdfa_learning.learn_pdfa][INFO] Populate root multiset. [2021-01-02 15:36:54,755][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 15:36:54,756][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 15:36:54,757][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 15:36:54,758][pdfa_learning.learn_pdfa][INFO] Biggest multiset has cardinality 0, done The learned automaton is: print ( \"Transitions: \" ) pprint ( pdfa . transitions ) render_automaton ( pdfa ) [2021-01-02 15:36:57,832][graphviz.files][DEBUG] write 201 bytes to '/tmp/tmpmq4hjn0x/output' [2021-01-02 15:36:57,834][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] Transitions: {(0, -1, 0.0, -1), (1, -1, 1.0, -1), (0, 0, 0.2852, 0), (0, 1, 0.7148, 1)} %3 fake 0 0 fake->0 0->0 0, 0.2852 1 1 0->1 1, 0.7148 -1 -1 1->-1 -1, 1.0 Example with 2 states. Now let's try to learn the following automaton: p1 = 0.4 p2 = 0.7 automaton = PDFA ( 3 , 2 , { 0 : { 0 : ( 1 , p1 ), 1 : ( 2 , 1 - p1 ), }, 1 : { 0 : ( 2 , 1 - p2 ), 1 : ( 1 , p2 ), }, 2 : { - 1 : ( - 1 , 1.0 ) } }, ) render_automaton ( automaton ) [2021-01-02 15:17:37,396][graphviz.files][DEBUG] write 248 bytes to '/tmp/tmpguqglne2/output' [2021-01-02 15:17:37,397][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 1 1 0->1 0, 0.4 2 2 0->2 1, 0.6 1->1 1, 0.7 1->2 0, 0.3 -1 -1 2->-1 -1, 1.0 generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . BALLE , sample_generator = generator , alphabet_size = automaton . alphabet_size , nb_samples = 20000 , delta = 0.1 , n = 10 , ) [2021-01-02 15:37:10,974][pdfa_learning.learn_pdfa][INFO] Parameters: (\"{'alphabet_size': 2,\\n\" \" 'dataset_size': None,\\n\" \" 'delta': 0.1,\\n\" \" 'epsilon': 0.1,\\n\" \" 'n': 10,\\n\" \" 'nb_samples': 20000,\\n\" \" 'sample_generator': \" '<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator object at ' '0x7f53fd4d4590>,\\n' \" 'with_ground': False,\\n\" \" 'with_infty_norm': True,\\n\" \" 'with_smoothing': False}\") [2021-01-02 15:37:10,976][pdfa_learning.learn_pdfa][INFO] Generating the sample. [2021-01-02 15:37:11,348][pdfa_learning.learn_pdfa][INFO] Average trace length: 2.4088. [2021-01-02 15:37:11,348][pdfa_learning.learn_pdfa][INFO] Populate root multiset. [2021-01-02 15:37:11,367][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 15:37:11,367][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 15:37:11,368][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 15:37:11,368][pdfa_learning.learn_pdfa][INFO] Biggest multiset has cardinality 0, done render_automaton ( pdfa ) [2021-01-02 15:37:13,469][graphviz.files][DEBUG] write 201 bytes to '/tmp/tmp41alblmt/output' [2021-01-02 15:37:13,471][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.2852 1 1 0->1 1, 0.7148 -1 -1 1->-1 -1, 1.0 References [1] Balle, Borja, Jorge Castro, and Ricard Gavald\u00e0. \"Learning probabilistic automata: A study in state distinguishability.\" Theoretical Computer Science 473 (2013): 46-60.","title":"Learn a PDFA using (Balle et al., 2013)"},{"location":"notebooks/03-pdfa-learning-balle/#pdfa-learning-balle-et-al-2013","text":"In this notebook, we will show how to use the implementation of PDFA learning, as described in [2]. In terms of APIs, the only things that change are the parameter algorithm to learn_pdfa (it must be Algorithm.BALLE ) and the set of parameters. See pdfa_learning.learn_pdfa.balle.params.py for all the details.","title":"PDFA Learning (Balle et al., 2013)"},{"location":"notebooks/03-pdfa-learning-balle/#example","text":"Utility functions to display SVGs. % matplotlib inline from pprint import pprint from helpers import render_automaton from pdfa_learning.learn_pdfa.base import learn_pdfa , Algorithm from pdfa_learning.learn_pdfa.utils.generator import MultiprocessedGenerator , SimpleGenerator from pdfa_learning.pdfa import PDFA","title":"Example"},{"location":"notebooks/03-pdfa-learning-balle/#example-with-1-state","text":"Let's use the following automaton to generate samples. p = 0.3 automaton = PDFA ( nb_states = 2 , alphabet_size = 2 , transition_dict = { 0 : { 0 : ( 0 , p ), 1 : ( 1 , 1 - p ), }, 1 : { - 1 : ( - 1 , 1.0 )} } ) render_automaton ( automaton ) [2021-01-02 15:36:50,713][graphviz.files][DEBUG] write 195 bytes to '/tmp/tmp4krev1q6/output' [2021-01-02 15:36:50,715][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.3 1 1 0->1 1, 0.7 -1 -1 1->-1 -1, 1.0 Now we will run the PAC learning algorithm to learn the above automaton. With respect to the previous guide, we have the following parameters: nb_samples is the number of samples. delta : is the probability of failure. n : is the upperbound on the number of states. generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . BALLE , sample_generator = generator , alphabet_size = automaton . alphabet_size , nb_samples = 20000 , delta = 0.1 , n = 10 , ) [2021-01-02 15:36:54,341][pdfa_learning.learn_pdfa][INFO] Parameters: (\"{'alphabet_size': 2,\\n\" \" 'dataset_size': None,\\n\" \" 'delta': 0.1,\\n\" \" 'epsilon': 0.1,\\n\" \" 'n': 10,\\n\" \" 'nb_samples': 20000,\\n\" \" 'sample_generator': \" '<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator object at ' '0x7f5410c6bf50>,\\n' \" 'with_ground': False,\\n\" \" 'with_infty_norm': True,\\n\" \" 'with_smoothing': False}\") [2021-01-02 15:36:54,343][pdfa_learning.learn_pdfa][INFO] Generating the sample. [2021-01-02 15:36:54,737][pdfa_learning.learn_pdfa][INFO] Average trace length: 2.4088. [2021-01-02 15:36:54,738][pdfa_learning.learn_pdfa][INFO] Populate root multiset. [2021-01-02 15:36:54,755][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 15:36:54,756][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 15:36:54,757][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 15:36:54,758][pdfa_learning.learn_pdfa][INFO] Biggest multiset has cardinality 0, done The learned automaton is: print ( \"Transitions: \" ) pprint ( pdfa . transitions ) render_automaton ( pdfa ) [2021-01-02 15:36:57,832][graphviz.files][DEBUG] write 201 bytes to '/tmp/tmpmq4hjn0x/output' [2021-01-02 15:36:57,834][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] Transitions: {(0, -1, 0.0, -1), (1, -1, 1.0, -1), (0, 0, 0.2852, 0), (0, 1, 0.7148, 1)} %3 fake 0 0 fake->0 0->0 0, 0.2852 1 1 0->1 1, 0.7148 -1 -1 1->-1 -1, 1.0","title":"Example with 1 state."},{"location":"notebooks/03-pdfa-learning-balle/#example-with-2-states","text":"Now let's try to learn the following automaton: p1 = 0.4 p2 = 0.7 automaton = PDFA ( 3 , 2 , { 0 : { 0 : ( 1 , p1 ), 1 : ( 2 , 1 - p1 ), }, 1 : { 0 : ( 2 , 1 - p2 ), 1 : ( 1 , p2 ), }, 2 : { - 1 : ( - 1 , 1.0 ) } }, ) render_automaton ( automaton ) [2021-01-02 15:17:37,396][graphviz.files][DEBUG] write 248 bytes to '/tmp/tmpguqglne2/output' [2021-01-02 15:17:37,397][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 1 1 0->1 0, 0.4 2 2 0->2 1, 0.6 1->1 1, 0.7 1->2 0, 0.3 -1 -1 2->-1 -1, 1.0 generator = MultiprocessedGenerator ( SimpleGenerator ( automaton ), nb_processes = 8 ) pdfa = learn_pdfa ( algorithm = Algorithm . BALLE , sample_generator = generator , alphabet_size = automaton . alphabet_size , nb_samples = 20000 , delta = 0.1 , n = 10 , ) [2021-01-02 15:37:10,974][pdfa_learning.learn_pdfa][INFO] Parameters: (\"{'alphabet_size': 2,\\n\" \" 'dataset_size': None,\\n\" \" 'delta': 0.1,\\n\" \" 'epsilon': 0.1,\\n\" \" 'n': 10,\\n\" \" 'nb_samples': 20000,\\n\" \" 'sample_generator': \" '<pdfa_learning.learn_pdfa.utils.generator.MultiprocessedGenerator object at ' '0x7f53fd4d4590>,\\n' \" 'with_ground': False,\\n\" \" 'with_infty_norm': True,\\n\" \" 'with_smoothing': False}\") [2021-01-02 15:37:10,976][pdfa_learning.learn_pdfa][INFO] Generating the sample. [2021-01-02 15:37:11,348][pdfa_learning.learn_pdfa][INFO] Average trace length: 2.4088. [2021-01-02 15:37:11,348][pdfa_learning.learn_pdfa][INFO] Populate root multiset. [2021-01-02 15:37:11,367][pdfa_learning.learn_pdfa][INFO] Iteration 0 [2021-01-02 15:37:11,367][pdfa_learning.learn_pdfa][INFO] Iteration 1 [2021-01-02 15:37:11,368][pdfa_learning.learn_pdfa][INFO] Iteration 2 [2021-01-02 15:37:11,368][pdfa_learning.learn_pdfa][INFO] Biggest multiset has cardinality 0, done render_automaton ( pdfa ) [2021-01-02 15:37:13,469][graphviz.files][DEBUG] write 201 bytes to '/tmp/tmp41alblmt/output' [2021-01-02 15:37:13,471][graphviz.backend][DEBUG] run ['dot', '-Kdot', '-Tsvg', '-O', 'output'] %3 fake 0 0 fake->0 0->0 0, 0.2852 1 1 0->1 1, 0.7148 -1 -1 1->-1 -1, 1.0","title":"Example with 2 states."},{"location":"notebooks/03-pdfa-learning-balle/#references","text":"[1] Balle, Borja, Jorge Castro, and Ricard Gavald\u00e0. \"Learning probabilistic automata: A study in state distinguishability.\" Theoretical Computer Science 473 (2013): 46-60.","title":"References"}]}